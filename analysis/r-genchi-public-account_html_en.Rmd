---
title: "**Text analysis of the Participatory Public Accounts of the management of Gendarmería de Chile between the years 2017 and 2020**"
subtitle: "Technical Report"
author: "Authors: Fabián Álvarez / Roberto Rodríguez - Updated by: Fabián Álvarez"
date: "1st version: 09/11/2020 - Last Update: 25/05/2022"
output: html_document
knit: (function(inputFile, encoding) {
  out_dir <- '../output/technical-reports';
  rmarkdown::render(inputFile,
    encoding=encoding,
    output_file=file.path(dirname(inputFile), out_dir, 'genchi-technical-report_en.html')
    )
  })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r 1_libraries, include=FALSE}
library(renv)
library(pdftools)
library(tidytext)
library(tidyr)
library(dplyr)
library(patchwork)
library(tm)
library(stringr)
library(readr)
library(ggplot2)
library(diffobj)
library(googleLanguageR)
```

# Introduction

The Participatory Public Accounts (P.P.A.) are open dialogue mechanisms that link the authorities of the State Administration bodies with citizenship and aim to inform about the management of public policies carried out, generate a feedback process that allows collecting the concerns and contributions of its participants and give an organized response to consultations arising in the process.

For this analysis, text analysis techniques are applied in R language to the public accounts of Gendarmería de Chile corresponding to the years 2018, 2019, 2020 and 2021 (2017, 2018, 2019 and 2020, respectively).

Gendarmerie de Chile is a Public Service, under the Ministry of Justice and Human Rights of the State of Chile, whose mission is to contribute to a safer society, guaranteeing the effective fulfillment of preventive detention and liberty deprivation or restriction sentences to whom the courts determine, providing conditions and benefits to the affected ones according to their quality as a person and to the human rights standards, developing social reintegration programs that tend to reduce the probabilities of criminal recidivism and promoting the elimination of criminal record as part of the reintegration process.

-- *Note: At the date of publication of this project, the P.P.A. of this year 2022 (management 2021) is still in development by Gendarmería de Chile, thus it is not included in this analysis.*

-- *Note: an API from Google Cloud Translation was used for the english version of this report.  To run this version you need to create an R environment variable called GL_AUTH which includes the json file path with the API key. To get the key you must create a Google Cloud Platform account and a Service Account for translation purposes.*

# Reading and cleaning files

First, we read the data source.  In our case, these are files in PDF format.

```{r 2_source|reading}
speech_2021 <- pdf_text("../data/discurso_2021_2020.pdf")
speech_2020 <- pdf_text("../data/discurso_2020_2019.pdf")
speech_2019 <- pdf_text("../data/discurso_2019_2018.pdf")
speech_2018 <- pdf_text("../data/discurso_2018_2017.pdf")
```

Then, we eliminate the first pages of the speeches since they contain elements that are not part of the public account. We do the same for the last pages.  In both cases, only when appropriate.

```{r 2_source|removing_pages}
speech_2021 <- speech_2021 %>% 
  .[-1] %>% 
  .[-13]
speech_2020 <- speech_2020 %>%
  .[-1:-2] %>% 
  .[-53:-56]
speech_2019 <- speech_2019 %>% 
  .[-1:-2]
speech_2018 <- speech_2018 %>% 
  .[-1]
```

The objects in each speech are separated, so we join them into one object for each speech.

```{r 2_source|concatenating}
speech_2021 <- paste(speech_2021, collapse = " ")
speech_2020 <- paste(speech_2020, collapse = " ")
speech_2019 <- paste(speech_2019, collapse = " ")
speech_2018 <- paste(speech_2018, collapse = " ")
```

The *stopwords* are those words that have no meaning for themselves. They only modify or join others, so we must remove them for the analysis.  To do this, we take words from the [Anatext](https://github.com/7PartidasDigital/AnaText/blob/master/datos/diccionarios/vacias.txt) repository that we have already downloaded previously. And we add additional words that we might find irrelevant.

```{r 2_source|stopwords, message=FALSE}
stopwords_es <- read_csv("../data/vacias.txt", col_names = TRUE, show_col_types = FALSE)
my_stopwords <- tibble(palabra = c("mil", "millones", "año", "años", "chile", "dado", 
                                   "dar", "debido", "decir", "acerca", "pesos",
                                   "fin", "ser", "respecto", "debe", "gran", "tiene",
                                   "tienen", "puede", "ir", "hace"))
more_stopwords <- tibble(palabra = c("cdp", "cerrado", "gendarmería", "fecha", "período", 
                                     "cuenta", "informe", "viii", "monto", "diariamente",
                                     "diferentes", "impacta", "enfocar", "deberá"))
```

## Regular Expressions and Stopwords

We search for regular expressions and stopwords to be discarded from the document.

### Speech 2021 (Management 2020)

We start dropping regular expressions from Speech 2021 and making some corrections.

```{r 3_cleaning1|regular_expressions_2021_2020}
speech_2021 <- speech_2021 %>%
  str_replace_all("\n", " ") %>% # Replace "\n" by space
  str_remove_all("“") %>% str_remove_all("”") %>% # Remove "" 
  str_remove_all("INTRODUCCIÓN") %>% 
  str_replace_all("\\d+\\s+\\S+gob\\.cl", " ") %>% # Pages
  str_replace_all("INFORME FINAL", " ") %>%
  str_replace_all("\\s\\S+\\.-", " ") %>% str_replace_all("VI\\.", " ") %>% # Numbering
  str_replace_all("\\s\\d+-\\s", " ") %>% 
  str_replace_all("\\s\\d\\.\\s", " ") %>% 
  str_replace_all("5\\.1", " ") %>% str_replace_all("5\\.2-", " ") %>% 
  str_replace_all("\\s[abcde]+\\)\\s", " ") %>% 
  str_replace_all("http\\S+\\s", " ") %>% # urls
  str_replace_all("SOCIEDAD\\S+\\s", " ") %>% 
  str_replace_all("Gendarmería de Chile", " ") %>% str_replace_all("Gendarmería", " ") %>% 
  str_replace_all("Institución.+Manríquez", " ") %>% 
  str_replace_all("con 64\\s+.+Nacional de Chile", " ") %>% str_replace_all("64 \\(1\\)", " ") %>% 
  str_replace_all("públicas65", "públicas") %>% str_replace_all("decisiones\\.66", "decisiones") %>% 
  str_replace_all("65\\s+Instructivo.+Transparencia\\.2015\\.", " ") %>% 
  str_replace_all("Informe Ejecutivo", " ") %>% 
  str_replace_all("informe Resumen Ejecutivo", " ") %>% 
  str_replace_all("\\Snforme final", " ") %>% 
  str_replace_all("\\Snforme.", " ")

```

```{r 3_cleaning1|additional_corrections}
speech_2021 <- speech_2021 %>% 
  str_replace_all("Cuentas Públicas Participativas", "Cuenta Pública Participativa ") %>% 
  str_replace_all("cuentas públicas", "cuenta pública") %>% 
  str_replace_all("COVID 19", "COVID-19") %>% 
  str_replace_all("\\sCOVID\\s", " COVID-19 ") %>% 
  str_remove_all("\\(Consejo para la transparencia\\.2015\\)") %>% 
  str_replace_all("Consejo de la Sociedad Civil \\(COSOC\\)", "Consejo de la Sociedad Civil") %>% 
  str_replace_all("Consejo de la Sociedad Civil", "COSOC") %>% 
  str_replace_all("CONSEJO DE LA SOCIEDAD CIVIL", "COSOC") %>% 
  str_remove_all("Unidad de Atención y Participación Ciudadana") %>% 
  str_remove_all("Unidad de Comunicaciones") %>% 
  str_replace_all("Unidades Penales", "Unidad Penal") %>% 
  str_remove_all("Departamento de Estadística y Estudios penitenciarios") %>% 
  str_remove_all("disponer") %>% 
  str_replace_all("pacientes", "paciente") %>% 
  str_replace_all("PACIENTES", "paciente") %>% 
  str_replace_all("paciente", "pacientes") %>% 
  str_replace_all("clínico", "clínica") %>% 
  stripWhitespace()
```

```{r 3_cleaning1|comparison, eval=FALSE, include=FALSE}
speech_2021_modif1 <- speech_2021
speech_2021_modif2 <- speech_2021 %>% 
  stripWhitespace()

#diffObj(speech_2021_modif1, speech_2021_modif2, mode="sidebyside")
diffChr(speech_2021_modif1, speech_2021_modif2, mode="sidebyside")
```

We turn the speech into a dataframe, separate its words and calculate its frequencies.

```{r 3_cleaning1|first_frequencies_2021_2020}
frequencies_2021 <- tibble(speech = speech_2021) %>% 
  unnest_tokens(output = palabra, input = speech, strip_numeric = TRUE) %>%
  count(palabra, sort = TRUE)
frequencies_2021
```

We remove the *stopwords* and recalculate the frequencies.

```{r 3_cleaning1|second_frequencies_2021_2020, message=FALSE}
frequencies_2021 <- frequencies_2021 %>% 
  anti_join(stopwords_es) %>% 
  anti_join(my_stopwords) %>% 
  anti_join(more_stopwords)
head(frequencies_2021)
```


### Speech 2020 (Management 2019)

We start dropping regular expressions from Speech 2020 and making some corrections.

```{r 3_cleaning2|regular_expressions_2020_2019}
speech_2020 <- speech_2020 %>%
  str_replace_all("\n", " ") %>% # Replace "\n" by space
  str_remove_all("“") %>% str_remove_all("”") %>% # Remove "" 
  str_replace_all("MINJU", "MINJUDDHH") %>% # Ministerio de Justicia y DDHH
  str_replace_all("MINJUDDHH-DDHH", "MINJUDDHH") %>% 
  str_replace_all("\\s+•\\s+", " ") %>% # Bullets
  str_replace_all("\\s\\S+\\.-\\s", " ") %>% 
  str_replace_all("\\s\\d-\\s", " ") %>% # Numbering
  str_replace_all("\\s\\d\\.\\s", " ") %>% 
  str_replace_all("\\s\\d\\d\\.\\s", " ") %>% 
  str_replace_all("\\s\\d\\.\\d\\s", " ") %>% 
  str_replace_all("\\s+[abcde]+\\)+\\s", " ") %>% 
  str_replace_all("\\s[abcde]\\.\\d\\)", " ") %>% 
  str_replace_all("19\\.-", " ") %>% # 
  str_remove_all("http\\S*") %>% # urls
  str_remove_all("www.\\S*") %>% # Remove web pages
  str_remove_all("Twitter.+gendarmeriacl") %>%  # Remove social networks
  str_remove_all("N° de internos heridos.+\\(S\\.I\\.G\\)") %>% # Remove Tables
  str_remove_all("A continuación, se expone un desglose.+Fuente: Departamento de Infraestructura") %>% # Remove Tables 
  str_remove_all("MATRICULADOS EN EDUCACIÓN SUPERIOR DICIEMBRE 2019.+Total\\s+163\\s+Fuente: Departamento Sistema Cerrado") %>% # Remove Tables 
  str_remove_all("\\s+Tabla Privados de Libertad Inscritos para dar PSU.+\\s+2046\\s+Fuente: Departamento Sistema Cerrado") %>% # Remove Tables 
  str_remove_all("\\s+Tabla Resultados PSU 2019 de Privados de Libertad, por región:.+\\s+13\\s+Fuente: Departamento Sistema Cerrado") %>% # Remove Tables 
  str_remove_all("\\s+INTERNOS PARTICIPANDO.+\\s+Automotriz\\s+Fuente: Departamento Sistema Cerrado") %>% # Remove Tables 
  str_remove_all("\\s+Eliminación de antecedentes:.+Fuente: Departamento Post Penitenciario") %>% # Remove Tables 
  str_remove_all("\\s+Intervención:.+\\s+37\\s+Fuente: Departamento Subsistema Cerrado") %>% # Remove Tables 
  str_remove_all("\\s+CANTIDAD DE CELULARES.+\\s+256\\s+Fuente: Subdirección Operativa") %>% # Remove Tables 
  str_remove_all("\\sCOVID: Estadística de contagios por región.+\\s+1357\\s+Fuente: Subdirección Operativa") %>% # Remove Tables 
  str_remove_all("\\s+Catastro.+\\s+167\\s+Fuente: Subdirección Operativa") %>% # Remove Tables 
  str_remove_all("\\sfecha:.+Fuente: Subdirección Operativa") %>% # Remove Tables 
  stripWhitespace() # Remove unnecessary spaces
```

```{r 3_cleaning2|additional_corrections}
speech_2020 <- speech_2020 %>% 
  str_replace_all("COVID\\s19", "COVID-19") %>% # Standardize COVID-19
  str_replace_all("COVID-\\s19", "COVID-19") %>% 
  str_replace_all("COVID:", "COVID-19") %>% 
  str_replace_all("Covid-19", "COVID-19") %>% 
  str_replace_all("Covid19", "COVID-19") %>% 
  str_replace_all("COVID y", "COVID-19 y") %>% 
  str_replace_all("cas2", "cas") %>% # Others
  str_replace_all("ransparencia\\.", "ransparencia ") %>% 
  str_replace_all("para la transparencia", "para la Transparencia") %>% 
  str_replace_all("s e g u r i d a d in t e r na", "seguridad interna") %>% 
  str_replace_all("d e l o s re c i n to s", "de los recintos") %>% 
  str_replace_all("p e n i te nc i a r io s", "penitenciarios") %>% 
  str_remove_all("Departamento Sistema Cerrado") %>% 
  str_remove_all("Departamento de Salud") %>% 
  str_remove_all("Departamento de DDHH") %>% 
  str_remove_all("Departamento DDHH") %>% 
  str_remove_all("Departamento de Promoción y Protección de los DDHH") %>% 
  str_remove_all("Departamento de Promoción y Protección de Derechos Humanos") %>% 
  str_remove_all("Departamento de Promoción y Protección de los Derechos Humanos") %>% 
  str_remove_all("Departamento de Infraestructura") %>% 
  str_remove_all("Departamento de Informática") %>% 
  str_remove_all("Departamento en el Sistema Cerrado") %>% 
  str_remove_all("Departamento") %>% 
  str_replace_all("autoridades sanitarias", "autoridad sanitaria") %>% 
  str_replace_all("condiciones sanitarias", "condición sanitaria") %>% 
  str_replace_all("residencias sanitarias", "residencia sanitaria") %>% 
  str_replace_all("restricciones sanitarias", "restricción sanitaria") %>% 
  str_replace_all("sanitarias", "sanitaria") %>% 
  str_replace_all("Sanitarias", "sanitaria") %>% 
  str_replace_all("contagios", "contagio") %>% str_replace_all("contagio", "contagios") %>% 
  str_remove_all("Departamento de Estadística y Estudios penitenciarios") %>%  
  str_replace_all("lesión", "lesiones") %>% 
  str_replace_all("Egresos", "egreso") %>% str_replace_all("egresos", "egreso") %>% 
  str_replace_all("egreso", "egresos") %>% 
  stripWhitespace() 
  
```

```{r 3_cleaning2|comparison, eval=FALSE, include=FALSE}
speech_2020_modif1 <- speech_2020
speech_2020_modif2 <- speech_2020 %>% 
  stripWhitespace() 

#diffObj(speech_2020_modif1, speech_2020_modif2, mode="sidebyside")
diffChr(speech_2020_modif1, speech_2020_modif2, mode="sidebyside")
```

We turn the speech into a dataframe, separate its words and calculate its frequencies.

```{r 3_cleaning2|first_frequencies_2020_2019}
frequencies_2020 <- tibble(speech = speech_2020) %>% 
  unnest_tokens(output = palabra, input = speech, strip_numeric = TRUE) %>%
  count(palabra, sort = TRUE)
frequencies_2020
```

We remove the *stopwords* and recalculate the frequencies.

```{r 3_cleaning2|second_frequencies_2020_2019, message=FALSE}
frequencies_2020 <- frequencies_2020 %>% 
  anti_join(stopwords_es) %>% 
  anti_join(my_stopwords) %>% 
  anti_join(more_stopwords)
head(frequencies_2020)
```

### Speech 2019 (Management 2018)

We start dropping regular expressions from Speech 2019 and making some corrections.

```{r 3_cleaning3|regular_expressions_2019_2018}
speech_2019 <- speech_2019 %>% 
  str_replace_all("\n", " ") %>% # Replace "\n" by space
  str_remove_all("Tabla rela.+\\s+Fuente: Departamento de Infraestructura de Gendarmería de Chile") %>%  # Remove Tables
  str_remove_all("Capacitaciones en cifras.+\\s+Fuente: Escuela Institucional") %>% 
  str_remove_all("Presupuesto Inicial.+\\s+Contabilidad y Presupuesto, Gendarmería de Chile") %>% 
  str_replace_all("\\s\\s\\s\\s\\d+\\s", " ") %>% # Page number
  str_replace_all("\\s\\d\\.\\s", " ") %>% # Numbering & bullets
  str_remove_all("1. PRESENTACIÓN ") %>% 
  str_replace_all("\\s\\d\\.\\d\\.\\d\\.\\s", " ") %>% 
  str_replace_all("\\s\\d\\.\\d\\.\\s", " ") %>% 
  str_replace_all("\\s•\\s", " ") %>% 
  str_replace_all("\\s-\\s", " ") %>% 
  str_replace_all("\\s\\S\\.\\s", " ") %>% 
  str_replace_all("Ministerio de Justicia y Derechos Humanos", "MINJUDDHH") %>% 
  str_replace_all("Ministerio de Justicia y DD.HH.", "MINJUDDHH") %>% 
  str_remove_all("N°")
```

```{r 3_cleaning3|additional_corrections}
speech_2019 <- speech_2019 %>% 
  str_replace_all("ETIntervención", "Intervención") %>% 
  str_replace_all("ETCapacitación", "Capacitación") %>% 
  str_replace_all("ETColocación", "Colocación") %>% 
  str_replace_all("APpsicosocial", "psicosocial") %>% 
  str_replace_all("", " ") %>% 
  str_replace_all("APestablecimiento", "establecimiento") %>%
  str_replace_all("Aapoyo", "apoyo") %>%
  str_replace_all("Aopermisos", "permisos") %>%
  str_replace_all("1terceros", "terceros") %>% 
  str_remove_all("“") %>% str_remove_all("”") %>% 
  str_replace_all("de \\+R", "de Proyecto +R") %>% 
  str_replace_all("Departamento de Contabilidad y Presupuesto", " ") %>% 
  str_replace_all("Departamento de Gestión de Personas", " ") %>% 
  str_replace_all("Departamento de Gestión y Desarrollo de Personas", " ") %>% 
  str_replace_all("Departamento de Salud", " ") %>% 
  str_replace_all("Departamentos de Inteligencia Penitenciaria\\s+y de\\s+Investigación Criminal", " ") %>% 
  str_replace_all("Departamento de Investigación y Análisis Penitenciario \\(DIAP\\)", " ") %>% 
  str_replace_all("departamentos de Salud e Informática", " ") %>% 
  str_replace_all("Departamento de Promoción y Protección de los Derechos Humanos", " ") %>% 
  str_replace_all("Departamento de Infraestructura", " ") %>% 
  str_replace_all("Subdepartamento de Servicios\\s+Especializados", " ") %>% 
  str_replace_all("Departamento de Control Penitenciario", " ") %>% 
  str_replace_all("departamentos y/o unidades", " ") %>% 
  str_remove_all("a Departamento") %>% 
  str_remove_all("términos") %>% 
  str_remove_all("mejorando") %>% 
  str_remove_all("desarrollar") %>% 
  str_remove_all("porcentaje") %>% 
  str_remove_all("Departamento de Estadística y Estudios penitenciarios") %>% 
  str_replace_all("\\Sstablecimientos", "establecimientos") %>% 
  str_replace_all("\\Saborales", "laboral") %>% 
  str_replace_all("\\Snternacionales", "internacional") %>% 
  str_replace_all("\\s\\Sompras\\s", " compra ") %>% str_replace_all("\\s\\Sompra\\s", " compras ") %>% 
  stripWhitespace() 

```

```{r 3_cleaning3|comparison, eval=FALSE, include=FALSE}
speech_2019_modif1 <- speech_2019
speech_2019_modif2 <- speech_2019 %>% 
  stripWhitespace() 

#diffObj(speech_2019_modif1, speech_2019_modif2, mode="sidebyside")
diffChr(speech_2019_modif1, speech_2019_modif2, mode="sidebyside")
```

We turn the speech into a dataframe, separate its words and calculate its frequencies.

```{r 3_cleaning3|first_frequencies_2019_2018}
frequencies_2019 <- tibble(speech = speech_2019) %>% 
  unnest_tokens(output = palabra, input = speech, strip_numeric = TRUE) %>%
  count(palabra, sort = TRUE)
frequencies_2019
```

We remove the *stopwords* and recalculate the frequencies.

```{r 3_cleaning3|second_frequencies_2019_2018, message=FALSE}
frequencies_2019 <- frequencies_2019 %>% 
  anti_join(stopwords_es) %>% 
  anti_join(my_stopwords) %>% 
  anti_join(more_stopwords)
head(frequencies_2019)
```

### Speech 2018 (Management 2017)

We start dropping regular expressions from Speech 2018 and making some corrections.

```{r 3_cleaning4|regular_expressions_2018_2017}
speech_2018 <- speech_2018 %>% 
  str_replace_all("\n", " ") %>% # Replace "\n" by space
  str_remove_all("\\s+Allanamientos\\s+.+854") %>% # Remove Tables
  str_remove_all("\\s+PROGRAMAS\\s+REINSERCIÓN\\s.+\\sLACTANTES") %>% 
  str_remove_all("Distribución Regional.+NACIONAL\\s+43") %>% 
  str_remove_all("siguiente detalle.+Total\\s+305") %>% 
  str_remove_all("Aspirante Oficiales P.+327 Hombres\\)") %>% 
  str_remove_all("\\s+N° de horas.+ARAUCANÍA\\)") %>% 
  str_remove_all("AÑO\\s+NOMBRE.+PUBLICA\\s+30") %>% 
  str_remove_all("II\\.\\s") %>% str_remove_all("I\\.\\s") %>% 
  str_replace_all("\\s\\d\\.\\s+", " ") %>% 
  str_replace_all("\\s•\\s", " ") %>% 
  str_remove_all("1 Fuente de datos: Estadística General Penitenciaria\\. Unidad de Estadística\\. Gendarmería de Chile") 
```


```{r 3_cleaning4|additional_corrections}
speech_2018 <- speech_2018 %>% 
  str_remove_all("N°") %>% 
  str_replace_all("Departamento del Sistema Cerrado\\.", " ") %>% 
  str_replace_all("Departamento de Recursos Humanos", " ") %>% 
  str_replace_all("multidisclinarios", "multidisciplinarios") %>% 
  str_replace_all("asociadas:Implementación", "asociadas Implementación") %>% 
  str_replace_all("pesos\\.Reposición", "pesos Reposición") %>% 
  str_replace_all("incendios:Programa", "incendios Programa") %>% 
  str_replace_all("Coyhaique\\.Mantención", "Coyhaique Mantención") %>% 
  str_replace_all("intervenidos", "intervenido") %>% str_replace_all("intervenido", "intervenidos") %>% 
  str_replace_all("\\Sstablecimientos", "establecimientos") %>% 
  str_replace_all("Laborales", "laboral") %>% 
  stripWhitespace()  
  
```

```{r 3_cleaning4|comparison, eval=FALSE, include=FALSE}
speech_2018_modif1 <- speech_2018
speech_2018_modif2 <- speech_2018 %>% 
  stripWhitespace()  

#diffObj(speech_2018_modif1, speech_2018_modif2, mode="sidebyside")
diffChr(speech_2018_modif1, speech_2018_modif2, mode="sidebyside")
```

We turn the speech into a dataframe, separate its words and calculate its frequencies.

```{r 3_cleaning4|first_frequencies_2018_2017}
frequencies_2018 <- tibble(speech = speech_2018) %>% 
  unnest_tokens(output = palabra, input = speech, strip_numeric = TRUE) %>%
  count(palabra, sort = TRUE)
frequencies_2018
```

We remove the *stopwords* and recalculate the frequencies.

```{r 3_cleaning4|second_frequencies_2018_2017, message=FALSE}
frequencies_2018 <- frequencies_2018 %>% 
  anti_join(stopwords_es) %>% 
  anti_join(my_stopwords) %>% 
  anti_join(more_stopwords)
head(frequencies_2018)
```


# One-word Analysis

First, we calculate and plot the most frequent words in each speech to subsequently perform a TF-IDF analysis. This analysis allows to determine the relevance of a word in a document regarding a set of documents.  It allows to answer the question: What concepts of one word stand out in a speech regarding the rest of the speeches?


## Frequencies

```{r _translate|reduce_df}
frequencies_2021_en <- frequencies_2021 %>% 
  slice_head(n = 10) 
frequencies_2020_en <- frequencies_2020 %>% 
  slice_head(n = 10) 
frequencies_2019_en <- frequencies_2019 %>% 
  slice_head(n = 10) 
frequencies_2018_en <- frequencies_2018 %>% 
  slice_head(n = 10) 
```

```{r _translate|freq_one-word_translation, message=FALSE}
googleLanguageR::gl_auth(Sys.getenv("GL_AUTH"))

frequencies_2021_en <- frequencies_2021_en %>% 
  mutate(
    word = gl_translate(
      palabra, 
      target = "en", 
      format = "text", 
      source = "es")$translatedText
    ) %>% 
  select(word, n) %>% 
  mutate(word = replace(word, word == "Health", "health")) %>% 
  mutate(word = replace(word, word == "developing", "development"))

frequencies_2020_en <- frequencies_2020_en %>% 
  mutate(
    word = gl_translate(
      palabra, 
      target = "en", 
      format = "text", 
      source = "es")$translatedText
    ) %>% 
  select(word, n)  %>% 
  mutate(word = replace(word, word == "internal", "inmates")) %>% 
  mutate(word = replace(word, word == "Rights", "rights")) 

frequencies_2019_en <- frequencies_2019_en %>% 
  mutate(
    word = gl_translate(
      palabra, 
      target = "en", 
      format = "text", 
      source = "es")$translatedText
    ) %>% 
  select(word, n)%>% 
  mutate(word = replace(word, word == "worked", "work")) %>% 
  mutate(word = replace(word, word == "officials", "employees")) %>% 
  mutate(word = replace(word, word == "Program", "program")) %>% 
  mutate(word = replace(word, word == "establishments", "facilities"))

frequencies_2018_en <- frequencies_2018_en %>% 
  mutate(
    word = gl_translate(
      palabra, 
      target = "en", 
      format = "text", 
      source = "es")$translatedText
    ) %>% 
  select(word, n) %>% 
  mutate(word = replace(word, word == "Program", "program")) %>% 
  mutate(word = replace(word, word == "establishments", "facilities")) %>% 
  mutate(word = replace(word, word == "worked", "work"))
```

We plot the most frequent words from each speech.

```{r 4_one-word_analysis|frequencies}
pic_2021 <- frequencies_2021_en %>% 
  ggplot(aes(y = reorder(word, n), n)) +
  geom_col(fill = "#dbb012") +
  geom_text(aes(label = n), size = 3, hjust = 0.2) +
  theme_minimal() +
  labs(y = NULL, x = "frequency") +
  ggtitle("Speech 2021") +
  theme(plot.title = element_text(hjust = 0.5))

pic_2020 <- frequencies_2020_en %>% 
  ggplot(aes(y = reorder(word, n), n)) +
  geom_col(fill = "#619cff") +
  geom_text(aes(label = n), size = 3, hjust = 0.2) +
  theme_minimal() +
  labs(y = NULL, x = "frequency") +
  ggtitle("Speech 2020") +
  theme(plot.title = element_text(hjust = 0.5))

pic_2019 <- frequencies_2019_en %>% 
  ggplot(aes(y = reorder(word, n), n)) +
  geom_col(fill = "#00ba38") +
  geom_text(aes(label = n), size = 3, hjust = 0.2) +
  theme_minimal() +
  labs(y = NULL, x = "frequency") +
  ggtitle("Speech 2019") +
  theme(plot.title = element_text(hjust = 0.5))

pic_2018 <- frequencies_2018_en %>% 
  ggplot(aes(y = reorder(word, n), n)) +
  geom_col(fill = "#f8766d") +
  geom_text(aes(label = n), size = 3, hjust = 0.2) +
  theme_minimal() +
  labs(y = NULL, x = "frequency") +
  ggtitle("Speech 2018") +
  theme(plot.title = element_text(hjust = 0.5))

(pic_2018 + pic_2019) / (pic_2020 + pic_2021)
```

```{r 4_one-word_analysis|frequencies_fig, include=FALSE}
png("../figs/one-word_frequencies_en.png", width = 1344, height = 960)
(pic_2018 + pic_2019) / (pic_2020 + pic_2021) 
dev.off()
```


## TF-IDF Analysis

We join the frequencies in a single dataframe, identifying words and frequencies with their respective speeches.

```{r 4_one-word_analysis|TF-IDF-one_data_frame}
frequencies_2021 <- frequencies_2021 %>% 
  mutate(discurso = "P.P.A. 2021", .before = palabra) 
frequencies_2020 <- frequencies_2020 %>% 
  mutate(discurso = "P.P.A. 2020", .before = palabra) 
frequencies_2019 <- frequencies_2019 %>% 
  mutate(discurso = "P.P.A. 2019", .before = palabra) 
frequencies_2018 <- frequencies_2018 %>% 
  mutate(discurso = "P.P.A. 2018", .before = palabra) 

messages <- bind_rows(frequencies_2018, frequencies_2019, frequencies_2020, frequencies_2021)
head(messages)
```

Then, we calculate the reverse frequencies of words.

```{r 4_one-word_analysis|TF-IDF_inverse_document_frequency}
messages_tfidf <- bind_tf_idf(messages, 
                              term = palabra, 
                              document = discurso,
                              n = n)
head(messages_tfidf) 

```

And we compare graphically.

```{r _translate|TF-IDF_one-word_plotting_translated, message=FALSE}
one_word_plot_en <- messages_tfidf %>%
  group_by(discurso) %>%
  top_n(5) %>% 
  mutate(
    word = gl_translate(
      palabra,
      target = "en",
      format = "text",
      source = "es")$translatedText
    ) %>% 
  select(-palabra) %>% 
  ungroup %>%
  mutate(word = replace(word, word == "establishments", "facilities")) %>% 
  mutate(word = replace(word, word == "means", "resources")) %>% 
  mutate(word = replace(word, word == "estates", "establishments")) %>% 
  mutate(word = replace(word, word == "expenses", "outgoing")) %>% 
  mutate(discurso = as.factor(discurso),
         word = reorder_within(word, tf_idf, discurso)
         ) %>%
    ggplot(aes(word, tf_idf, fill = discurso)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~discurso, scales = "free_y") +
    coord_flip() +
    scale_x_reordered() +
    scale_y_continuous(expand = c(0,0)) +
    labs(y = "tf-idf", x = NULL)
one_word_plot_en
```

```{r 4_one-word_analysis|TF-IDF_plotting_fig, include=FALSE}
png("../figs/one-word_tf-idf_en.png", width = 1344, height = 960)
one_word_plot_en
dev.off()
```

In the speech of the Participatory Public Account (P.P.A.) 2018, work, training and *labor* placement, and those *convicts* that have been intervened was emphasized. Likewise, it was given accounts about *resources* executed during 2017, financed by Law of Budget. *Armament* protection policy is also mentioned in special units.

During 2019, the P.P.A. Speech focused on highlighting the intervention, training and *labor* placement programs, as well as the *labor* activities carried out within the prison *facilities* during 2018. In the same way, the *surveillance* of persons deprived of liberty, the adoption of norms and good practices adjusted to *international* law and compliance with commitments with *international* organizations were emphasized.

We see that the words *infections* and *covid* took the attention of Speech 2020, which makes a lot of sense in attention to the *sanitary* emergency of pandemic that began in that year. On the other hand, it is reported the publication of a recidivism study that considered *outgoing* persons deprived of liberty in 2016. In addition, attention was paid to the large number of detainees during 2019 that were received with obvious *injuries* from police institutions, for which protocols to check health status were approved.

Finally, the 2021 speech of the P.P.A. emphasized two major themes. The first, related to *mental* health and the derivation of possible *patients* deprived of liberty with needs for psychological *clinical* care in the field of individual *psychotherapy.* This, especially that during 2020 the health risk of pandemic was maintained. The second topic addressed the development of a *Participatory* Public Account with greater social inclusion and with transmission via streaming for the second consecutive year.


# Bigram Analysis

Let's define some *stopwords* to additionally discard with those already defined.  We make some additional corrections and calculate the frequency of the bigrams for each document.

```{r 5_two-words_analysis|more_stopwords}
bi_stopwords <- tibble(palabra = c("cuenta", "cuentas", "deberán", "realizar", "diferentes")) 
```

```{r 5_two-words_analysis|2021-2020_corrections}
speech_2021 <- speech_2021 %>% 
  str_remove_all("políticas,") %>% str_remove_all("planes") %>% str_remove_all("programas") %>% 
  str_remove_all("Intrapenitenciaria") %>% str_remove_all("INTRAPENITENCIARIA") %>% 
  str_replace_all("\\Snidad \\Senal", "establecimientos penitenciarios") %>% 
  str_replace_all("del establecimiento", "de los establecimientos penitenciarios") %>% 
  str_remove_all("\\Suenta \\Sública \\Sarticipativa") %>% 
  stripWhitespace()
```

```{r 5_two-words_analysis|2021-2020_comparison, eval=FALSE, include=FALSE}
speech_2021_modif1 <- speech_2021
speech_2021_modif2 <- speech_2021 %>% 
  stripWhitespace()

#diffObj(speech_2021_modif1, speech_2021_modif2, mode="sidebyside")
diffChr(speech_2021_modif1, speech_2021_modif2, mode="sidebyside")
```

```{r 5_two-words_analysis|2020-2019_corrections}
speech_2020 <- speech_2020 %>% 
  str_replace_all("\\Snidad \\Senal", "unidades penales") %>% 
  str_replace_all("\\Snidades \\Senales", "establecimientos penitenciarios") %>% 
  str_replace_all("visita virtuales", "visitas virtuales") %>% 
  str_replace_all("visita virtual", "visitas virtuales") %>% 
  str_replace_all("espacio físico", "espacios físicos") %>% 
  str_replace_all("\\Sstablecimiento \\Senitenciario", "establecimientos penitenciarios") %>% 
  str_replace_all("establecimiento penal", "establecimientos penitenciarios") %>% 
  str_replace_all("teléfono celular", "teléfonos móviles") %>% 
  str_replace_all("teléfono móvil", "teléfonos móviles") %>% 
  str_remove_all("Centro de Estudios Justicia & Sociedad") %>% 
  stripWhitespace()
```

```{r 5_two-words_analysis|2020-2019_comparison, eval=FALSE, include=FALSE}
speech_2020_modif1 <- speech_2020
speech_2020_modif2 <- speech_2020 %>% 
  stripWhitespace()

#diffObj(speech_2020_modif1, speech_2020_modif2, mode="sidebyside")
diffChr(speech_2020_modif1, speech_2020_modif2, mode="sidebyside")
```

```{r 5_two-words_analysis|2019-2018_corrections}
speech_2019 <- speech_2019 %>% 
  str_remove_all("igual forma") %>% 
  str_remove_all("Centro de Cumplimiento Penitenciario") %>% 
  str_remove_all("Centros de Cumplimiento Penitenciario") %>% 
  str_replace_all("unidades penales", "establecimientos penitenciarios") %>% 
  str_replace_all("unidad penal", "establecimientos penitenciarios") %>% 
  str_replace_all("\\Sstablecimiento \\Senal", "establecimientos penitenciarios") %>% 
  str_replace_all("\\Sstablecimientos \\Senales", "establecimientos penitenciarios") %>% 
  str_replace_all("diferentes penales", "diferentes establecimientos penitenciarios") %>% 
  str_replace_all("\\Sirección \\Segional", "direcciones regionales") %>% 
  stripWhitespace()
```

```{r 5_two-words_analysis|2019-2018_comparison, eval=FALSE, include=FALSE}
speech_2019_modif1 <- speech_2019
speech_2019_modif2 <- speech_2019 %>% 
  stripWhitespace()

#diffObj(speech_2019_modif1, speech_2019_modif2, mode="sidebyside")
diffChr(speech_2019_modif1, speech_2019_modif2, mode="sidebyside")
```

```{r 5_two-words_analysis|2018-2017_corrections}
speech_2018 <- speech_2018 %>% 
  str_replace_all("establecimiento penitenciario", "establecimientos penitenciarios") %>% 
  str_replace_all("establecimientos penales", "establecimientos penitenciarios") %>% 
  str_replace_all("algunos establecimientos", "algunos establecimientos penitenciarios") %>% 
  str_replace_all("73 establecimientos", "73 establecimientos penitenciarios") %>% 
  str_replace_all("prohibidas en establecimientos", "prohibidas en establecimientos penitenciarios") %>% 
  str_replace_all("establecimientos institucionales", "establecimientos penitenciarios") %>% 
  str_replace_all("condena en establecimientos", "condena en establecimientos penitenciarios") %>% 
  str_replace_all("otros establecimientos", "otros establecimientos penitenciarios") %>% 
  str_replace_all("últimos establecimientos", "últimos establecimientos penitenciarios") %>% 
  str_replace_all("equipamiento del establecimiento", "equipamiento de establecimientos penitenciarios") %>% 
  str_replace_all("nuevo establecimiento", "nuevos establecimientos penitenciarios") %>% 
  str_replace_all("tener un establecimiento", "tener establecimientos penitenciarios") %>% 
  str_replace_all("10 establecimientos", "10 establecimientos penitenciarios") %>% 
  str_remove_all("Departamento del \\Sistema \\Serrado") %>% 
  str_replace_all("\\s\\Sistema \\Serrado", " subsistema cerrado") %>% 
  str_replace_all("unidades penales", "establecimientos penitenciarios") %>% 
  str_remove_all("siguientes iniciativas") %>% 
  str_replace_all("direcciones técnicas regionales", "unidades técnicas") %>%
  str_replace_all("unidades técnicas regionales", "unidades técnicas") %>% 
  str_replace_all("\\s\\Sonvenio\\s", " convenios suscritos ") %>% 
  str_replace_all("convenios con", "convenios suscritos con") %>% 
  str_replace_all("convenios en", "convenios suscritos en") %>% 
  str_replace_all("de allanamiento en", "de allanamientos simultáneos en") %>% 
  str_replace_all("estos allanamientos", "estos allanamientos simultáneos") %>% 
  stripWhitespace()
```

```{r 5_two-words_analysis|2018-2017_comparison, eval=FALSE, include=FALSE}
speech_2018_modif1 <- speech_2018
speech_2018_modif2 <- speech_2018 %>% 
  stripWhitespace()

#diffObj(speech_2018_modif1, speech_2018_modif2, mode="sidebyside")
diffChr(speech_2018_modif1, speech_2018_modif2, mode="sidebyside")
```


## Frequencies

```{r 5_two-words_analysis|bigram_frequencies_2021-2020}
bigram_2021 <- speech_2021 %>% 
  tibble(speech = speech_2021) %>% 
  unnest_tokens(input = speech,
                output = palabra,
                token = "ngrams",
                n = 2) %>% 
  filter(!is.na(palabra)) %>% 
  count(palabra, sort = TRUE) %>% 
  separate(palabra,
           into = c("palabra_1", "palabra_2"),
           sep = " ") %>% 
  filter(!palabra_1 %in% stopwords_es$palabra) %>% 
  filter(!palabra_2 %in% stopwords_es$palabra) %>% 
  filter(!palabra_1 %in% my_stopwords$palabra) %>% 
  filter(!palabra_2 %in% my_stopwords$palabra) %>%
  filter(!palabra_1 %in% bi_stopwords$palabra) %>% 
  filter(!palabra_2 %in% bi_stopwords$palabra) %>%
  mutate(palabra = paste(palabra_1, palabra_2, sep = " "), .before = n) %>% 
  dplyr::select(-c(palabra_1, palabra_2))
head(bigram_2021)
```

```{r 5_two-words_analysis|bigram_frequencies_2020-2019}
bigram_2020 <- speech_2020 %>% 
  tibble(speech = speech_2020) %>% 
  unnest_tokens(input = speech,
                output = palabra,
                token = "ngrams",
                n = 2) %>% 
  filter(!is.na(palabra)) %>% 
  count(palabra, sort = TRUE) %>% 
  separate(palabra,
           into = c("palabra_1", "palabra_2"),
           sep = " ") %>% 
  filter(!palabra_1 %in% stopwords_es$palabra) %>% 
  filter(!palabra_2 %in% stopwords_es$palabra) %>% 
  filter(!palabra_1 %in% my_stopwords$palabra) %>% 
  filter(!palabra_2 %in% my_stopwords$palabra) %>%
  filter(!palabra_1 %in% bi_stopwords$palabra) %>% 
  filter(!palabra_2 %in% bi_stopwords$palabra) %>%
  mutate(palabra = paste(palabra_1, palabra_2, sep = " "), .before = n) %>% 
  dplyr::select(-c(palabra_1, palabra_2))
head(bigram_2020)
```

```{r 5_two-words_analysis|bigram_frequencies_2019-2018}
bigram_2019 <- speech_2019 %>% 
  tibble(speech = speech_2019) %>% 
  unnest_tokens(input = speech,
                output = palabra,
                token = "ngrams",
                n = 2) %>% 
  filter(!is.na(palabra)) %>% 
  count(palabra, sort = TRUE) %>% 
  separate(palabra,
           into = c("palabra_1", "palabra_2"),
           sep = " ") %>% 
  filter(!palabra_1 %in% stopwords_es$palabra) %>% 
  filter(!palabra_2 %in% stopwords_es$palabra) %>% 
  filter(!palabra_1 %in% my_stopwords$palabra) %>% 
  filter(!palabra_2 %in% my_stopwords$palabra) %>%
  filter(!palabra_1 %in% bi_stopwords$palabra) %>% 
  filter(!palabra_2 %in% bi_stopwords$palabra) %>%
  mutate(palabra = paste(palabra_1, palabra_2, sep = " "), .before = n) %>% 
  dplyr::select(-c(palabra_1, palabra_2))
head(bigram_2019)
```

```{r 5_two-words_analysis|bigram_frequencies_2018-2017}
bigram_2018 <- speech_2018 %>% 
  tibble(speech = speech_2018) %>% 
  unnest_tokens(input = speech,
                output = palabra,
                token = "ngrams",
                n = 2) %>% 
  filter(!is.na(palabra)) %>% 
  count(palabra, sort = TRUE) %>% 
  separate(palabra,
           into = c("palabra_1", "palabra_2"),
           sep = " ") %>% 
  filter(!palabra_1 %in% stopwords_es$palabra) %>% 
  filter(!palabra_2 %in% stopwords_es$palabra) %>% 
  filter(!palabra_1 %in% my_stopwords$palabra) %>% 
  filter(!palabra_2 %in% my_stopwords$palabra) %>%
  filter(!palabra_1 %in% bi_stopwords$palabra) %>% 
  filter(!palabra_2 %in% bi_stopwords$palabra) %>%
  mutate(palabra = paste(palabra_1, palabra_2, sep = " "), .before = n) %>% 
  dplyr::select(-c(palabra_1, palabra_2))
head(bigram_2018)
```

```{r _translate|freq_two-word_translation, message=FALSE}
bigram_2021_en <- bigram_2021 %>% 
  slice_head(n = 10) %>% 
  mutate(
    word = gl_translate(
      palabra, 
      target = "en", 
      format = "text", 
      source = "es")$translatedText
    ) %>% 
  select(word, n) %>% 
  mutate(word = replace(word, word == "penitentiary establishments", "penitentiary facilities")) %>% 
  mutate(word = replace(word, word == "Budget Execution", "budget execution")) %>% 
  mutate(word = replace(word, word == "Psychological attention", "psychological attention")) 

bigram_2020_en <- bigram_2020 %>% 
  slice_head(n = 10) %>% 
  mutate(
    word = gl_translate(
      palabra, 
      target = "en", 
      format = "text", 
      source = "es")$translatedText
    ) %>% 
  select(word, n) %>% 
  mutate(word = replace(word, word == "penitentiary establishments", "penitentiary facilities")) %>% 
  mutate(word = replace(word, word == "Physical spaces", "physical spaces")) %>% 
  mutate(word = replace(word, word == "Nacional level", "national level")) 

bigram_2019_en <- bigram_2019 %>% 
  slice_head(n = 10) %>% 
  mutate(
    word = gl_translate(
      palabra, 
      target = "en", 
      format = "text", 
      source = "es")$translatedText
    ) %>% 
  select(word, n) %>% 
  mutate(word = replace(word, word == "penitentiary establishments", "penitentiary facilities")) %>% 
  mutate(word = replace(word, word == "regional addresses", "regional managements")) %>% 
  mutate(word = replace(word, word == "Nacional level", "national level")) 

bigram_2018_en <- bigram_2018 %>% 
  slice_head(n = 10) %>% 
  mutate(
    word = gl_translate(
      palabra, 
      target = "en", 
      format = "text", 
      source = "es")$translatedText
    ) %>% 
  select(word, n) %>% 
  mutate(word = replace(word, word == "penitentiary establishments", "penitentiary facilities")) %>% 
  mutate(word = replace(word, word == "Nacional level", "national level")) %>% 
  mutate(word = replace(word, word == "prison system", "penitentiary system")) 

```


We plot the most frequent bigrams.

```{r 5_two-words_analysis|bigram_frequencies}

fig_2021 <- bigram_2021_en %>% 
  ggplot(aes(y = reorder(word, n), n)) +
  geom_col(fill = "#dbb012") +
  geom_text(aes(label = n), size = 3, hjust = 0.2) +
  theme_minimal() +
  labs(y = NULL, x = "frequency") +
  ggtitle("Speech 2021") +
  theme(plot.title = element_text(hjust = 0.5))

fig_2020 <- bigram_2020_en %>% 
  ggplot(aes(y = reorder(word, n), n)) +
  geom_col(fill = "#619cff") +
  geom_text(aes(label = n), size = 3, hjust = 0.2) +
  theme_minimal() +
  labs(y = NULL, x = "frequency") +
  ggtitle("Speech 2020") +
  theme(plot.title = element_text(hjust = 0.5))

fig_2019 <- bigram_2019_en %>% 
  ggplot(aes(y = reorder(word, n), n)) +
  geom_col(fill = "#00ba38") +
  geom_text(aes(label = n), size = 3, hjust = 0.2) +
  theme_minimal() +
  labs(y = NULL, x = "frequency") +
  ggtitle("Speech 2019") +
  theme(plot.title = element_text(hjust = 0.5))

fig_2018 <- bigram_2018_en %>% 
  ggplot(aes(y = reorder(word, n), n)) +
  geom_col(fill = "#f8766d") +
  geom_text(aes(label = n), size = 3, hjust = 0.2) +
  theme_minimal() +
  labs(y = NULL, x = "frequency") +
  ggtitle("Speech 2018") +
  theme(plot.title = element_text(hjust = 0.5))

(fig_2018 + fig_2019) / (fig_2020 + fig_2021)
```

```{r 5_two-words_analysis|frequencies_fig, include=FALSE}
png("../figs/two-words_frequencies_en.png", width = 1344, height = 960)
(fig_2018 + fig_2019) / (fig_2020 + fig_2021)
dev.off()
```


## TF-IDF Analysis

We join the frequencies in a single dataframe, identifying words and frequencies with their respective speeches.

```{r 5_two-words_analysis|TF-IDF-one_data_frame}

frequencies_2021 <- bigram_2021 %>% 
  mutate(discurso = "P.P.A. 2021", .before = palabra) 
frequencies_2020 <- bigram_2020 %>% 
  mutate(discurso = "P.P.A. 2020", .before = palabra) 
frequencies_2019 <- bigram_2019 %>% 
  mutate(discurso = "P.P.A. 2019", .before = palabra) 
frequencies_2018 <- bigram_2018 %>% 
  mutate(discurso = "P.P.A. 2018", .before = palabra) 

messages <- bind_rows(frequencies_2018, frequencies_2019, frequencies_2020, frequencies_2021)
head(messages)
```

Then, we calculate the reverse frequencies of words.

```{r 5_two-words_analysis|TF-IDF_inverse_document_frequency}
messages_tfidf <- bind_tf_idf(messages, 
                              term = palabra, 
                              document = discurso,
                              n = n)
head(messages_tfidf) 
```

And we compare graphically.

```{r 5_two-words_analysis|TF-IDF_plotting_TF-IDF, message=FALSE}
two_words_plot_en <- messages_tfidf %>%
  group_by(discurso) %>%
  top_n(5) %>%
  mutate(
    word = gl_translate(
      palabra,
      target = "en",
      format = "text",
      source = "es")$translatedText
    ) %>% 
  select(-palabra) %>% 
  ungroup %>%
  mutate(word = replace(word, word == "Higher cost", "higher cost")) %>%
  mutate(word = replace(word, word == "regional addresses", "regional managements")) %>%
  mutate(word = replace(word, word == "Physical spaces", "physical spaces")) %>%
  mutate(word = replace(word, word == "executive Summary", "executive summary")) %>%
  mutate(discurso = as.factor(discurso),
         word = reorder_within(word, tf_idf, discurso)) %>%
  ggplot(aes(word, tf_idf, fill = discurso)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~discurso, scales = "free_y") +
  coord_flip() +
  scale_x_reordered() +
  scale_y_continuous(expand = c(0,0)) +
  labs(y = "tf-idf", x = NULL)
two_words_plot_en
```

```{r 5_two-words_analysis|TF-IDF_plotting_fig, include=FALSE}
png("../figs/two-words_tf-idf_en.png", width = 1344, height = 960)
two_words_plot_en
dev.off()
```

The speech of the Participatory Public Account (P.P.A.) of the year 2018 highlighted the execution of activities through *signed agreements* in 2017 with various public entities, corporations, foundations and universities, both at the central and regional level, managed and implemented by the different regional *technical units* and of penitentiary facilities. During this year, *simultaneous raids* were developed in various regions, allowing to seize various illicit and prohibited species.

In the 2019 speech, the coordination of *Regional Offices* with the units of the closed, opened and postpenitentiary subsystems was emphasized, in order to carry out joint activities for public-private links. Other activities in 2018 were executed in the field of *Human Rights* through training for officials and updating resolutions and administrative acts. There were also execution of projects to implement, expand, replace and maintain *electronic security* equipment, with the aim of complementing human perimeter surveillance.

The bigram analysis stands out again that the P.P.A. Speech of the year 2020 focused on the pandemic situation by *covid 19* and in some actions taken as a result of it, such as the implementation of rooms for *virtual visits*, allow the limited use of *mobile phones* for the communication of inmates with their relatives, and relocation of inmates to reduce the probability of infections due to lack of *physical spaces* and their disinfection.

Lastly, the 2021 speech addressed the activities carried out in 2020 related to *clinical care* and the derivation of patients with *mental health* issues in pandemic context. On the other hand, it was highlighted the participation of citizens in the structure and content of the P.P.A. *Executive Summary* and its availability to download from the *institutional website*. A citizen consultation was also answered about the *Opening Roads* program from the Ministry of Social Development.




